
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{nhanes\_univariate\_analyses}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{univariate-data-analyses---nhanes-case-study}{%
\subsection{Univariate data analyses - NHANES case
study}\label{univariate-data-analyses---nhanes-case-study}}

Here we will demonstrate how to use Python and
\href{https://pandas.pydata.org/}{Pandas} to perform some basic analyses
with univariate data, using the 2015-2016 wave of the
\href{https://www.cdc.gov/nchs/nhanes/index.htm}{NHANES} study to
illustrate the techniques.

    The following import statements make the libraries that we will need
available. Note that in a Jupyter notebook, you should generally use the
\texttt{\%matplotlib\ inline} directive, which would not be used when
running a script outside of the Jupyter environment.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\end{Verbatim}


    Next we will load the NHANES data from a file.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{da} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{nhanes\PYZus{}2015\PYZus{}2016.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \hypertarget{frequency-tables}{%
\subsubsection{Frequency tables}\label{frequency-tables}}

The
\href{https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html}{value\_counts}
method can be used to determine the number of times that each distinct
value of a variable occurs in a data set. In statistical terms, this is
the ``frequency distribution'' of the variable. Below we show the
frequency distribution of the
\href{https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm\#DMDEDUC2}{DMDEDUC2}
variable, which is a variable that reflects a person's level of
educational attainment. The \texttt{value\_counts} method produces a
table with two columns. The first column contains all distinct observed
values for the variable. The second column contains the number of times
each of these values occurs. Note that the table returned by
\texttt{value\_counts} is actually a Pandas data frame, so can be
further processed using any Pandas methods for working with data frames.

The numbers 1, 2, 3, 4, 5, 9 seen below are integer codes for the 6
possible non-missing values of the DMDEDUC2 variable. The meaning of
these codes is given in the NHANES codebook located
\href{https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm\#DMDEDUC2}{here},
and will be discussed further below. This table shows, for example, that
1621 people in the data file have DMDEDUC=4, which indicates that the
person has completed some college, but has not graduated with a
four-year degree.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:} 4.0    1621
        5.0    1366
        3.0    1186
        1.0     655
        2.0     643
        9.0       3
        Name: DMDEDUC2, dtype: int64
\end{Verbatim}
            
    Note that the \texttt{value\_counts} method excludes missing values. We
confirm this below by adding up the number of observations with a
DMDEDUC2 value equal to 1, 2, 3, 4, 5, or 9 (there are 5474 such rows),
and comparing this to the total number of rows in the data set, which is
5735. This tells us that there are 5735 - 5474 = 261 missing values for
this variable (other variables may have different numbers of missing
values).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+m+mi}{1621} \PY{o}{+} \PY{l+m+mi}{1366} \PY{o}{+} \PY{l+m+mi}{1186} \PY{o}{+} \PY{l+m+mi}{655} \PY{o}{+} \PY{l+m+mi}{643} \PY{o}{+} \PY{l+m+mi}{3}\PY{p}{)} \PY{c+c1}{\PYZsh{} Manually sum the frequencies}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
5474
5474
(5735, 28)

    \end{Verbatim}

    Another way to obtain this result is to locate all the null (missing)
values in the data set using the
\href{https://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html}{isnull}
Pandas function, and count the number of such locations.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{n}{pd}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}5}]:} 261
\end{Verbatim}
            
    In some cases it is useful to
\href{https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.replace.html}{replace}
integer codes with a text label that reflects the code's meaning. Below
we create a new variable called `DMDEDUC2x' that is recoded with text
labels, then we generate its frequency distribution.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{da}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DMDEDUC2x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZlt{}9}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{9\PYZhy{}11}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{HS/GED}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Some college/AA}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{College}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} 
                                               \PY{l+m+mi}{7}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Refused}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Don}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{t know}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
        \PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2x}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}6}]:} Some college/AA    1621
        College            1366
        HS/GED             1186
        <9                  655
        9-11                643
        Don't know            3
        Name: DMDEDUC2x, dtype: int64
\end{Verbatim}
            
    We will also want to have a relabeled version of the gender variable, so
we will construct that now as well. We will follow a convention here of
appending an `x' to the end of a categorical variable's name when it has
been recoded from numeric to string (text) values.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{da}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RIAGENDRx}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{da}\PY{o}{.}\PY{n}{RIAGENDR}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{1}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Male}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Female}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
\end{Verbatim}


    For many purposes it is more relevant to consider the proportion of the
sample with each of the possible category values, rather than the number
of people in each category. We can do this as follows:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{x} \PY{o}{=} \PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2x}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} x is just a name to hold this value temporarily}
        \PY{n}{x} \PY{o}{/} \PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:} Some college/AA    0.296127
        College            0.249543
        HS/GED             0.216661
        <9                 0.119657
        9-11               0.117464
        Don't know         0.000548
        Name: DMDEDUC2x, dtype: float64
\end{Verbatim}
            
    In some cases we will want to treat the missing response category as
another category of observed response, rather than ignoring it when
creating summaries. Below we create a new category called ``Missing'',
and assign all missing values to it usig
\href{https://pandas.pydata.org/pandas-docs/stable/missing_data.html\#filling-missing-values-fillna}{fillna}.
Then we recalculate the frequency distribution. We see that 4.6\% of the
responses are missing.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{n}{da}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DMDEDUC2x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2x}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Missing}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2x}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
        \PY{n}{x} \PY{o}{/} \PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}9}]:} Some college/AA    0.282650
        College            0.238187
        HS/GED             0.206800
        <9                 0.114211
        9-11               0.112119
        Missing            0.045510
        Don't know         0.000523
        Name: DMDEDUC2x, dtype: float64
\end{Verbatim}
            
    \hypertarget{numerical-summaries}{%
\subsubsection{Numerical summaries}\label{numerical-summaries}}

A quick way to get a set of numerical summaries for a quantitative
variable is with the
\href{https://pandas.pydata.org/pandas-docs/stable/basics.html\#summarizing-data-describe}{describe}
data frame method. Below we demonstrate how to do this using the body
weight variable
(\href{https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BMX_I.htm\#BMXWT}{BMXWT}).
As with many surveys, some data values are missing, so we explicitly
drop the missing cases using the
\href{https://pandas.pydata.org/pandas-docs/stable/missing_data.html\#dropping-axis-labels-with-missing-data-dropna}{dropna}
method before generating the summaries.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{da}\PY{o}{.}\PY{n}{BMXWT}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}10}]:} count    5666.000000
         mean       81.342676
         std        21.764409
         min        32.400000
         25\%        65.900000
         50\%        78.200000
         75\%        92.700000
         max       198.900000
         Name: BMXWT, dtype: float64
\end{Verbatim}
            
    It's also possible to calculate individual summary statistics from one
column of a data set. This can be done using Pandas methods, or with
numpy functions:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{x} \PY{o}{=} \PY{n}{da}\PY{o}{.}\PY{n}{BMXWT}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Extract all non\PYZhy{}missing values of BMXWT into a variable called \PYZsq{}x\PYZsq{}}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} Pandas method}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} Numpy function}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{median}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} 50th percentile, same as the median}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{l+m+mi}{75}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} 75th percentile}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{quantile}\PY{p}{(}\PY{l+m+mf}{0.75}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} Pandas method for quantiles, equivalent to 75th percentile}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
81.34267560889516
81.34267560889516
78.2
78.2
92.7
92.7

    \end{Verbatim}

    Next we look at frequencies for a systolic blood pressure measurement
(\href{https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I.htm\#BPXSY1}{BPXSY1}).
``BPX'' here is the NHANES prefix for blood pressure measurements,
``SY'' stands for ``systolic'' blood pressure (blood pressure at the
peak of a heartbeat cycle), and ``1'' indicates that this is the first
of three systolic blood presure measurements taken on a subject.

A person is generally considered to have pre-hypertension when their
systolic blood pressure is between 120 and 139, or their diastolic blood
pressure is between 80 and 89. Considering only the systolic condition,
we can calculate the proprotion of the NHANES sample who would be
considered to have pre-hypertension.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXSY1} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{l+m+mi}{120}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXSY2} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{139}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} \PYZdq{}\PYZam{}\PYZdq{} means \PYZdq{}and\PYZdq{}}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:} 0.3741935483870968
\end{Verbatim}
            
    Next we calculate the propotion of NHANES subjects who are
pre-hypertensive based on diastolic blood pressure.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXDI1} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{l+m+mi}{80}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXDI2} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{89}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}13}]:} 0.14803836094158676
\end{Verbatim}
            
    Finally we calculate the proportion of NHANES subjects who are
pre-hypertensive based on either systolic or diastolic blood pressure.
Since some people are pre-hypertensive under both criteria, the
proportion below is less than the sum of the two proportions calculated
above.

Since the combined systolic and diastolic condition for pre-hypertension
is somewhat complex, below we construct temporary variables `a' and `b'
that hold the systolic and diastolic pre-hypertensive status separately,
then combine them with a ``logical or'' to obtain the final status for
each subject.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{a} \PY{o}{=} \PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXSY1} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{l+m+mi}{120}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXSY2} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{139}\PY{p}{)}
         \PY{n}{b} \PY{o}{=} \PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXDI1} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{l+m+mi}{80}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXDI2} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{89}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{a} \PY{o}{|} \PY{n}{b}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} \PYZdq{}|\PYZdq{} means \PYZdq{}or\PYZdq{}}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
0.43975588491717527

    \end{Verbatim}

    Blood pressure measurements are affected by a phenomenon called ``white
coat anxiety'', in which a subject's bood pressure may be slightly
elevated if they are nervous when interacting with health care
providers. Typically this effect subsides if the blood pressure is
measured several times in sequence. In NHANES, both systolic and
diastolic blood pressure are meausred three times for each subject (e.g.
\href{https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I.htm\#BPXSY2}{BPXSY2}
is the second measurement of systolic blood pressure). We can calculate
the extent to which white coat anxiety is present in the NHANES data by
looking a the mean difference between the first two systolic or
diastolic blood pressure measurements.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXSY1} \PY{o}{\PYZhy{}} \PY{n}{da}\PY{o}{.}\PY{n}{BPXSY2}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXDI1} \PY{o}{\PYZhy{}} \PY{n}{da}\PY{o}{.}\PY{n}{BPXDI2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
0.6749860309182343
0.3490407897187558

    \end{Verbatim}

    \hypertarget{graphical-summaries}{%
\subsubsection{Graphical summaries}\label{graphical-summaries}}

Quantitative variables can be effectively summarized graphically. Below
we see the distribution of body weight (in Kg), shown as a histogram. It
is evidently right-skewed.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BMXWT}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}16}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x7fca61ebbd68>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_32_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Next we look at the histogram of systolic blood pressure measurements.
You can see that there is a tendency for the measurements to be rounded
to the nearest 5 or 10 units.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{BPXSY1}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}17}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x7fca61bd8ef0>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_34_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    To compare several distributions, we can use side-by-side boxplots.
Below we compare the distributions of the first and second systolic
blood pressure measurements (BPXSY1, BPXSY2), and the first and second
diastolic blood pressure measurements
(\href{https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I.htm\#BPXDI1}{BPXDI1},
BPXDI2). As expected, diastolic measurements are substantially lower
than systolic measurements. Above we saw that the second blood pressure
reading on a subject tended on average to be slightly lower than the
first measurement. This difference was less than 1 mm/Hg, so is not
visible in the ``marginal'' distributions shown below.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{n}{bp} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{da}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{BPXSY1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{BPXSY2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{BPXDI1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{BPXDI2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}\PY{p}{)}
         \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{bp}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Blood pressure in mm/Hg}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_36_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{stratification}{%
\subsubsection{Stratification}\label{stratification}}

One of the most effective ways to get more information out of a dataset
is to divide it into smaller, more uniform subsets, and analyze each of
these ``strata'' on its own. We can then formally or informally compare
the findings in the different strata. When working with human subjects,
it is very common to stratify on demographic factors such as age, sex,
and race.

To illustrate this technique, consider blood pressure, which is a value
that tends to increase with age. To see this trend in the NHANES data,
we can
\href{https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html}{partition}
the data into age strata, and construct side-by-side boxplots of the
systolic blood pressure (SBP) distribution within each stratum. Since
age is a quantitative variable, we need to create a series of ``bins''
of similar SBP values in order to stratify the data. Each box in the
figure below is a summary of univariate data within a specific
population stratum (here defined by age).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{n}{da}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{agegrp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{RIDAGEYR}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{18}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{,} \PY{l+m+mi}{40}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{60}\PY{p}{,} \PY{l+m+mi}{70}\PY{p}{,} \PY{l+m+mi}{80}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} Create age strata based on these cut points}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Make the figure wider than default (12cm wide by 5cm tall)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{agegrp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{BPXSY1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{da}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Make boxplot of BPXSY1 stratified by age group}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}19}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x7fca5b97d278>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_38_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Taking this a step further, it is also the case that blood pressure
tends to differ between women and men. While we could simply make two
side-by-side boxplots to illustrate this contrast, it would be a bit odd
to ignore age after already having established that it is strongly
associated with blood pressure. Therefore, we will doubly stratify the
data by gender and age.

We see from the figure below that within each gender, older people tend
to have higher blood pressure than younger people. However within an age
band, the relationship between gender and systolic blood pressure is
somewhat complex -- in younger people, men have substantially higher
blood pressures than women of the same age. However for people older
than 50, this relationship becomes much weaker, and among people older
than 70 it appears to reverse. It is also notable that the variation of
these distributions, reflected in the height of each box in the boxplot,
increases with age.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{da}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{agegrp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{RIDAGEYR}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{18}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{,} \PY{l+m+mi}{40}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{60}\PY{p}{,} \PY{l+m+mi}{70}\PY{p}{,} \PY{l+m+mi}{80}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{agegrp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{BPXSY1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{hue}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RIAGENDRx}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{da}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}20}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x7fca5ba372e8>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_40_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    When stratifying on two factors (here age and gender), we can group the
boxes first by age, and within age bands by gender, as above, or we can
do the opposite -- group first by gender, and then within gender group
by age bands. Each approach highlights a different aspect of the data.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{n}{da}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{agegrp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{da}\PY{o}{.}\PY{n}{RIDAGEYR}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{18}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{,} \PY{l+m+mi}{40}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{60}\PY{p}{,} \PY{l+m+mi}{70}\PY{p}{,} \PY{l+m+mi}{80}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
         \PY{n}{sns}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RIAGENDRx}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{BPXSY1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{hue}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{agegrp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{da}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}21}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x7fca5b8c1710>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_42_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Stratification can also be useful when working with categorical
variables. Below we look at the frequency distribution of educational
attainment (``DMDEDUC2'') within 10-year age bands. While ``some
college'' is the most common response in all age bands, up to around age
60 the second most common response is ``college'' (i.e.~the person
graduated from college with a four-year degree). However for people over
50, there are as many or more people with only high school or general
equivalency diplomas (HS/GED) than there are college graduates.

\textbf{Note on causality and confounding:} An important role of
statistics is to aid researchers in identifying causes underlying
observed differences. Here we have seen differences in both blood
pressure and educational attainment based on age. It is plausible that
aging directly causes blood pressure to increase. But in the case of
educational attainment, this is actually a ``birth cohort effect''.
NHANES is a cross sectional survey (all data for one wave were collected
at a single point in time). People who were, say, 65 in 2015 (when these
data were collected), were college-aged around 1970, while people who
were in their 20's in 2015 were college-aged in around 2010 or later.
Over the last few decades, it has become much more common for people to
at least begin a college degree than it was in the past. Therefore,
younger people as a group have higher educational attainment than older
people as a group. As these young people grow older, the cross sectional
relationship between age and educational attainment will change.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n}{da}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{agegrp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DMDEDUC2x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}22}]:} agegrp    DMDEDUC2x      
         (18, 30]  Some college/AA    364
                   College            278
                   HS/GED             237
                   Missing            128
                   9-11                99
                   <9                  47
         (30, 40]  Some college/AA    282
                   College            264
                   HS/GED             182
                   9-11               111
                   <9                  93
         (40, 50]  Some college/AA    262
                   College            260
                   HS/GED             171
                   9-11               112
                   <9                  98
         (50, 60]  Some college/AA    258
                   College            220
                   HS/GED             220
                   9-11               122
                   <9                 104
         (60, 70]  Some college/AA    238
                   HS/GED             192
                   College            188
                   <9                 149
                   9-11               111
         (70, 80]  Some college/AA    217
                   HS/GED             184
                   <9                 164
                   College            156
                   9-11                88
                   Don't know           3
         Name: DMDEDUC2x, dtype: int64
\end{Verbatim}
            
    We can also stratify jointly by age and gender to explore how
educational attainment varies by both of these factors simultaneously.
In doing this, it is easier to interpret the results if we
\href{https://pandas.pydata.org/pandas-docs/stable/reshaping.html\#reshaping-by-stacking-and-unstacking}{pivot}
the education levels into the columns, and normalize the counts so that
they sum to 1. After doing this, the results can be interpreted as
proportions or probabilities. One notable observation from this table is
that for people up to age around 60, women are more likely to have
graduated from college than men, but for people over aged 60, this
relationship reverses.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{n}{dx} \PY{o}{=} \PY{n}{da}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{o}{\PYZti{}}\PY{n}{da}\PY{o}{.}\PY{n}{DMDEDUC2x}\PY{o}{.}\PY{n}{isin}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Don}\PY{l+s+s2}{\PYZsq{}}\PY{l+s+s2}{t know}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Missing}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{p}{:}\PY{p}{]}  \PY{c+c1}{\PYZsh{} Eliminate rare/missing values}
         \PY{n}{dx} \PY{o}{=} \PY{n}{dx}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{agegrp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RIAGENDRx}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DMDEDUC2x}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
         \PY{n}{dx} \PY{o}{=} \PY{n}{dx}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
         \PY{n}{dx} \PY{o}{=} \PY{n}{dx}\PY{o}{.}\PY{n}{unstack}\PY{p}{(}\PY{p}{)} \PY{c+c1}{\PYZsh{} Restructure the results from \PYZsq{}long\PYZsq{} to \PYZsq{}wide\PYZsq{}}
         \PY{n}{dx} \PY{o}{=} \PY{n}{dx}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{/}\PY{n}{x}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{c+c1}{\PYZsh{} Normalize within each stratum to get proportions}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{dx}\PY{o}{.}\PY{n}{to\PYZus{}string}\PY{p}{(}\PY{n}{float\PYZus{}format}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Limit display to 3 decimal places}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
DMDEDUC2x           9-11    <9  College  HS/GED  Some college/AA
agegrp   RIAGENDRx                                              
(18, 30] Female    0.080 0.049    0.282   0.215            0.374
         Male      0.117 0.042    0.258   0.250            0.333
(30, 40] Female    0.089 0.097    0.314   0.165            0.335
         Male      0.151 0.103    0.251   0.227            0.269
(40, 50] Female    0.110 0.106    0.299   0.173            0.313
         Male      0.142 0.112    0.274   0.209            0.262
(50, 60] Female    0.117 0.102    0.245   0.234            0.302
         Male      0.148 0.123    0.231   0.242            0.256
(60, 70] Female    0.118 0.188    0.195   0.206            0.293
         Male      0.135 0.151    0.233   0.231            0.249
(70, 80] Female    0.105 0.225    0.149   0.240            0.281
         Male      0.113 0.180    0.237   0.215            0.255

    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
